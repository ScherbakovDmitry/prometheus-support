# M-Lab prometheus recording rules.
#
# Before adding a new recording rule, review the general documentation and best
# practices.
#
#  * https://prometheus.io/docs/querying/rules/
#  * https://prometheus.io/docs/practices/rules/
#
# NOTE: As of 2017-11, the Prometheus v1.x series evaluates all rules in
# parallel. So, rule evaluation order is not guaranteed, and dependencies
# between rules are not respected. Using recording rules on the right hand
# side of an expression can have undefined behavior and may result in recording
# old data or other errors. This is also true for Alerts. This limitation is
# fixed in the Prometheus v2.x series.
#
# TODO: Prometheus v2.x rules are evaluated in order.
#
#    https://github.com/prometheus/prometheus/blob/v1.8.2/rules/manager.go#L254
#
# DO:
#  * Do use raw prometheus expressions on the right hand side of a new rule.
#  * "Recording rules should be of the general form level:metric:operations."
#  * Do use irate with a range that is 4x scrape_interval.
#
# DO NOT:
#  * Do not use recording rules on the right hand side of a new rule.
#  * Do not overwrite a metric name with itself.
#  * Do not use 'label_replace' to overwrite a metric name.
#  * Do not use rate with a range less than 4x the scrape_interval.


# Precalculate the increase of ipv4 and ipv6 sidestream connections.
ipv4_and_ipv6:sidestream_connection_count:increase2m =
    increase(sidestream_connection_count{type=~"ipv4|ipv6"}[2m])

# Precalculate the sum of sidestream connections per machine.
instance:sidestream_connection_count:increase2m =
    sum by(instance) (increase(sidestream_connection_count{type=~"ipv4|ipv6"}[2m]))

# Precalculate the sum of sidestream connections per experiment "last six bits".
lsb:sidestream_connection_count:increase2m =
    sum by(lsb) (increase(sidestream_connection_count{type=~"ipv4|ipv6"}[2m]))



## NDT Early Warning aggregation rules.
#
# Rules are evaluated every global.evaluation_interval seconds. When
# scrape_interval equals the evaluation_interval, there are potential races for
# short range operators, e.g. 2m when the eval and scrape intervals are 1m. At
# evaluation time, not every timeseries will contain 2 points in a 2m window.
#
# If we want to calculate the rate over 2m and increase the likelihood that we
# see at least two points we must use irate with a larger window, e.g. 4x the
# scrape interval. In our case this is 4m. irate only uses the last two samples
# to calculate an instantaneous rate.

# Per-machine inotify creation rates, using only c2s_snaplog + s2c_snaplog files.
# Units: requests per minute.
machine:inotify_extension_create:rpm2m =
    # NOTE: using 'without' instead of 'by' preserves all other labels.
    60.0 * sum without(ext) (irate(inotify_extension_create_total{ext=~".*_snaplog"}[4m]))

# TODO: aggregate on per-machine interface aliases when available.
# Per-switch "Out" (i.e. Download) bits per second. We use irate to calculate
# rates over the last two samples only.
# Units: bits per second.
switch:ifHCOutOctets:bps2m =
    8 * irate(ifHCOutOctets{ifAlias="uplink"}[4m])

# Per-machine maximum ratio of time spent performing I/O on all devices.
# Units: none
machine:node_disk_io_time_ms:max_ratio2m =
    max without(device) (irate(node_disk_io_time_ms{service="nodeexporter"}[4m])) / 1000

# NDT vserver disk quota utilization, 12 hour estimate.
# Units: KB
ndt:vdlimit_used:predict_linear1h_12h =
    predict_linear(vdlimit_used{experiment="ndt.iupui"}[1h], 12*60*60)
